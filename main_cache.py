# GitHub: https://github.com/naotaka1128/llm_app_codes/chapter_010/main_cache_new.py

import streamlit as st
import uuid  # thread_id ìƒì„±ìš©

# ============================================================
# [ìˆ˜ì •] LangChain 1.0.0+ ë²„ì „ ëŒ€ì‘
# - ê¸°ì¡´: create_tool_calling_agent + AgentExecutor ì¡°í•©
# - ë³€ê²½: create_agent ë‹¨ì¼ APIë¡œ í†µí•© (ë” ê°„ê²°í•œ ì½”ë“œ)
# - ì´ìœ : LangChain 1.0.0ì—ì„œ ì—ì´ì „íŠ¸ ìƒì„± APIê°€ ë‹¨ìˆœí™”ë¨
# ============================================================
from langchain.agents import create_agent
from langchain.agents.middleware import SummarizationMiddleware  # ëŒ€í™” ìš”ì•½ ë¯¸ë“¤ì›¨ì–´
from langgraph.checkpoint.memory import InMemorySaver  # ëŒ€í™” ìƒíƒœ ì €ì¥ì†Œ

# models
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
from langchain_google_genai import ChatGoogleGenerativeAI

# custom tools
from tools.fetch_qa_content import fetch_qa_content
from tools.fetch_stores_by_prefecture import fetch_stores_by_prefecture
from src.cache import Cache

# ============================================================
# [ìˆ˜ì •] ìŠ¤íŠ¸ë¦¬ë° í•¸ë“¤ëŸ¬ ë³€ê²½
# - ê¸°ì¡´: StreamlitCallbackHandler (LangChain ë ˆê±°ì‹œ)
# - ë³€ê²½: StreamlitLanggraphHandler (LangGraph í˜¸í™˜)
# - ì´ìœ : create_agentê°€ ë‚´ë¶€ì ìœ¼ë¡œ LangGraph ê¸°ë°˜ìœ¼ë¡œ ë™ì‘í•˜ë¯€ë¡œ
#         LangGraph ì „ìš© í•¸ë“¤ëŸ¬ ì‚¬ìš© í•„ìš”
# ============================================================
from youngjin_langchain_tools import StreamlitLanggraphHandler

###### dotenvë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê²½ìš°ëŠ” ì‚­ì œí•´ì£¼ì„¸ìš” ######
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    import warnings
    warnings.warn(
        "dotenv not found. Please make sure to set your environment variables manually.",
        ImportWarning,
    )
################################################


@st.cache_data
def load_system_prompt(file_path):
    with open(file_path, "r", encoding="utf-8") as f:
        return f.read()


# ============================================================
# Streamlit UI Functions
# ============================================================
def init_page():
    st.set_page_config(page_title="ê³ ê° ì§€ì›", page_icon="ğŸ»")
    st.header("ê³ ê° ì§€ì›ğŸ»")
    st.sidebar.title("Options")


def init_messages():
    clear_button = st.sidebar.button("Clear Conversation", key="clear")
    if clear_button or "messages" not in st.session_state:
        welcome_message = (
            "ì˜ì§„ëª¨ë°”ì¼ ê³ ê°ì§€ì›ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤. ì§ˆë¬¸ì„ ì…ë ¥í•´ ì£¼ì„¸ìš” ğŸ»"
        )
        st.session_state.messages = [{"role": "assistant", "content": welcome_message}]
        # [ìˆ˜ì •] ë©”ëª¨ë¦¬ ê´€ë¦¬ ë°©ì‹ ë³€ê²½
        # - ê¸°ì¡´: ConversationBufferWindowMemory (LangChain ë ˆê±°ì‹œ)
        # - ë³€ê²½: InMemorySaver + thread_id ì¡°í•© (LangGraph ë°©ì‹)
        # - ì´ìœ : create_agentëŠ” LangGraph ê¸°ë°˜ìœ¼ë¡œ ë™ì‘í•˜ë©°, checkpointerë¥¼ í†µí•´ ëŒ€í™” ìƒíƒœë¥¼ ê´€ë¦¬í•¨
        st.session_state["checkpointer"] = InMemorySaver()
        st.session_state["thread_id"] = str(uuid.uuid4())

    if len(st.session_state.messages) == 1:
        st.session_state["first_question"] = True
    else:
        st.session_state["first_question"] = False


def select_model(temperature=0):
    models = ("GPT-5 mini", "GPT-5.2", "Claude Sonnet 4.5", "Gemini 2.5 Flash")
    model = st.sidebar.radio("ì‚¬ìš©í•  ëª¨ë¸ ì„ íƒ:", models)
    if model == "GPT-5 mini":
        return ChatOpenAI(temperature=temperature, model="gpt-5-mini")
    elif model == "GPT-5.2":
        return ChatOpenAI(temperature=temperature, model="gpt-5.2")
    elif model == "Claude Sonnet 4.5":
        return ChatAnthropic(
            temperature=temperature, model="claude-sonnet-4-5-20250929"
        )
    elif model == "Gemini 2.5 Flash":
        return ChatGoogleGenerativeAI(temperature=temperature, model="gemini-2.5-flash")


# ============================================================
# [ìˆ˜ì •] ì—ì´ì „íŠ¸ ìƒì„± ë°©ì‹ ë³€ê²½
# - ê¸°ì¡´: create_tool_calling_agent + AgentExecutor ì¡°í•© (LangChain 0.x)
# - ë³€ê²½: create_agent ë‹¨ì¼ API (LangChain 1.0+)
# - ì´ìœ : ì½”ë“œ ê°„ì†Œí™” + checkpointer ê¸°ë°˜ ìƒíƒœ ê´€ë¦¬ + ë¯¸ë“¤ì›¨ì–´ ì§€ì›
# ============================================================
def create_customer_support_agent():
    tools = [fetch_qa_content, fetch_stores_by_prefecture]
    custom_system_prompt = load_system_prompt("./prompt/system_prompt.txt")
    llm = select_model()

    # [ìˆ˜ì •] SummarizationMiddleware ì¶”ê°€
    # - ëŒ€í™”ê°€ ê¸¸ì–´ì§€ë©´ ìë™ìœ¼ë¡œ ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ìš”ì•½
    summarization_middleware = SummarizationMiddleware(
        model=llm,
        max_tokens_before_summary=8000,
        messages_to_keep=10,
    )

    # [ìˆ˜ì •] create_agent ì‚¬ìš© (system_prompt ì§ì ‘ ì „ë‹¬, checkpointer ì‚¬ìš©)
    agent = create_agent(
        model=llm,
        tools=tools,
        system_prompt=custom_system_prompt,
        checkpointer=st.session_state["checkpointer"],
        middleware=[summarization_middleware],
        debug=True
    )

    return agent


# ============================================================
# Main Function
# - [ìˆ˜ì •] StreamlitLanggraphHandler ì‚¬ìš© (ê¸°ì¡´ StreamlitCallbackHandler ëŒ€ì²´)
# ============================================================
def main():
    init_page()
    init_messages()
    customer_support_agent = create_customer_support_agent()

    cache = Cache()

    for msg in st.session_state.messages:
        st.chat_message(msg["role"]).write(msg["content"])

    if prompt := st.chat_input(placeholder="ë²•ì¸ ëª…ì˜ë¡œ ê³„ì•½ì´ ê°€ëŠ¥í•œê°€ìš”?"):
        st.chat_message("user").write(prompt)
        st.session_state.messages.append({"role": "user", "content": prompt})

        # ì²« ë²ˆì§¸ ì§ˆë¬¸ì¸ ê²½ìš° ìºì‹œ í™•ì¸
        if st.session_state["first_question"]:
            if cache_content := cache.search(query=prompt):
                st.chat_message("assistant").write(f"(cache) {cache_content}")
                st.session_state.messages.append(
                    {"role": "assistant", "content": cache_content}
                )
                st.stop()

        with st.chat_message("assistant"):
            # [ìˆ˜ì •] StreamlitLanggraphHandler ì‚¬ìš© (ê¸°ì¡´ StreamlitCallbackHandler ëŒ€ì²´)
            handler = StreamlitLanggraphHandler(
                container=st.container(),
                expand_new_thoughts=True,
                max_thought_containers=4,
            )

            # [ìˆ˜ì •] ì—ì´ì „íŠ¸ í˜¸ì¶œ ë°©ì‹ ë³€ê²½
            response = handler.invoke(
                agent=customer_support_agent,
                input={"messages": [{"role": "user", "content": prompt}]},
                config={"configurable": {"thread_id": st.session_state["thread_id"]}}
            )

            if response:
                st.session_state.messages.append({"role": "assistant", "content": response})

        # ì²« ë²ˆì§¸ ì§ˆë¬¸ì¸ ê²½ìš° ìºì‹œì— ì €ì¥
        if st.session_state["first_question"] and response:
            cache.save(prompt, response)


if __name__ == "__main__":
    main()
